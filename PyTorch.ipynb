{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "WIQw9nNB-yeR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Download and unpack data from Kaggle**"
      ]
    },
    {
      "metadata": {
        "id": "25PKA_MWbpMV",
        "colab_type": "code",
        "outputId": "627d30da-ef10-4238-fabb-30003fd42622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L2iiJrFMbyxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "user = ''\n",
        "key = ''\n",
        " \n",
        "if '.kaggle' not in os.listdir('/root'):\n",
        "    !mkdir ~/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 666 /root/.kaggle/kaggle.json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (user, key))\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWP5wZhrbyK7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Y3fRqPRbyTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip train.zip -d train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TAGz07hPbyav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dsciy2Xwbyif",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip train_labels.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sWaSxmEYbyqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ceac84fe-7b00-4f7d-f3a6-9172237a9332"
      },
      "cell_type": "code",
      "source": [
        "!unzip sample_submission.csv.zip"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HGOrgNI1fH0p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preparing data**"
      ]
    },
    {
      "metadata": {
        "id": "HXUOzCnQ9Mf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHzzBjQLo9r6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Parameters for model\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 8\n",
        "num_classes = 2\n",
        "batch_size = 128\n",
        "learning_rate = 0.002\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zSPSHP4QnD4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('train_labels.csv')\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "train_path = 'train'\n",
        "test_path = 'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cLPLijI89MZt",
        "colab_type": "code",
        "outputId": "813d2e5b-f379-46ef-ed74-e6091a44bb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(labels, stratify=labels.label, test_size=0.1)\n",
        "len(train), len(val)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198022, 22003)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "zMG6nUpLoeAD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Simple custom generator*"
      ]
    },
    {
      "metadata": {
        "id": "TrZrjAag9Mcc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df_data, data_dir = './', transform=None):\n",
        "        super().__init__()\n",
        "        self.df = df_data.values\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_name,label = self.df[index]\n",
        "        img_path = os.path.join(self.data_dir, img_name+'.tif')\n",
        "        image = cv2.imread(img_path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SY1UoiUE9MXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trans_train = transforms.Compose([transforms.ToPILImage(),\n",
        "                                  transforms.Pad(64, padding_mode='reflect'),\n",
        "                                  transforms.RandomHorizontalFlip(), \n",
        "                                  transforms.RandomVerticalFlip(),\n",
        "                                  transforms.RandomRotation(20), \n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "trans_valid = transforms.Compose([transforms.ToPILImage(),\n",
        "                                  transforms.Pad(64, padding_mode='reflect'),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "dataset_train = MyDataset(df_data=train, data_dir=train_path, transform=trans_train)\n",
        "dataset_valid = MyDataset(df_data=val, data_dir=train_path, transform=trans_valid)\n",
        "\n",
        "loader_train = DataLoader(dataset = dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "loader_valid = DataLoader(dataset = dataset_valid, batch_size=batch_size//2, shuffle=False, num_workers=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6EYKwgYrlE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ]
    },
    {
      "metadata": {
        "id": "cbJ5Jhev7WS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "****Public Score 0.9539****"
      ]
    },
    {
      "metadata": {
        "id": "R44ZqjJ1NUFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# NOTE: CLASS IS INHERITED FROM nn.Module\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # ancestor constructor call\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.fc = nn.Linear(64 * 29 * 29, 2)  # !!!\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        # print(x.shape) lifehack to find out the desired dimension for the Liner layer\n",
        "        x = x.view(-1, 64 * 29 * 29)  # !!!\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RnpLc7927iLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wh8USTzi_5tr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Important note: You may notice that in lines with # !!! there is not very clear 64 * 29 *29. This is the dimension of the picture before the FC layers (H x W x C), then you have to calculate it manually (in Keras, for example, .Flatten () does everything for you). However, there is one life hack — just make print (x.shape) in forward () (commented out line). You will see the size (batch_size, C, H, W) - you need to multiply everything except the first (batch_size), this will be the first dimension of Linear (), and it is in C H W that you need to \"expand\" x before feeding to Linear ()."
      ]
    },
    {
      "metadata": {
        "id": "MrplU0pR9MBU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = SimpleConvNet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BV5Pb3cI9L-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDUCB_qt2EOg",
        "colab_type": "code",
        "outputId": "6663f5c4-82cd-4773-e7f1-4a72717eb4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2057
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "total_step = len(loader_train)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(loader_train):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/8], Step [100/1548], Loss: 0.5498\n",
            "Epoch [1/8], Step [200/1548], Loss: 0.4306\n",
            "Epoch [1/8], Step [300/1548], Loss: 0.5542\n",
            "Epoch [1/8], Step [400/1548], Loss: 0.4787\n",
            "Epoch [1/8], Step [500/1548], Loss: 0.5290\n",
            "Epoch [1/8], Step [600/1548], Loss: 0.4210\n",
            "Epoch [1/8], Step [700/1548], Loss: 0.4518\n",
            "Epoch [1/8], Step [800/1548], Loss: 0.4656\n",
            "Epoch [1/8], Step [900/1548], Loss: 0.4175\n",
            "Epoch [1/8], Step [1000/1548], Loss: 0.4213\n",
            "Epoch [1/8], Step [1100/1548], Loss: 0.6913\n",
            "Epoch [1/8], Step [1200/1548], Loss: 0.6548\n",
            "Epoch [1/8], Step [1300/1548], Loss: 0.4138\n",
            "Epoch [1/8], Step [1400/1548], Loss: 0.5629\n",
            "Epoch [1/8], Step [1500/1548], Loss: 0.3609\n",
            "Epoch [2/8], Step [100/1548], Loss: 0.3705\n",
            "Epoch [2/8], Step [200/1548], Loss: 0.3680\n",
            "Epoch [2/8], Step [300/1548], Loss: 0.3773\n",
            "Epoch [2/8], Step [400/1548], Loss: 0.3150\n",
            "Epoch [2/8], Step [500/1548], Loss: 0.3285\n",
            "Epoch [2/8], Step [600/1548], Loss: 0.3779\n",
            "Epoch [2/8], Step [700/1548], Loss: 0.4119\n",
            "Epoch [2/8], Step [800/1548], Loss: 0.2917\n",
            "Epoch [2/8], Step [900/1548], Loss: 0.3088\n",
            "Epoch [2/8], Step [1000/1548], Loss: 0.3307\n",
            "Epoch [2/8], Step [1100/1548], Loss: 0.5431\n",
            "Epoch [2/8], Step [1200/1548], Loss: 0.3555\n",
            "Epoch [2/8], Step [1300/1548], Loss: 0.2299\n",
            "Epoch [2/8], Step [1400/1548], Loss: 0.4597\n",
            "Epoch [2/8], Step [1500/1548], Loss: 0.4638\n",
            "Epoch [3/8], Step [100/1548], Loss: 0.2729\n",
            "Epoch [3/8], Step [200/1548], Loss: 0.3139\n",
            "Epoch [3/8], Step [300/1548], Loss: 0.5351\n",
            "Epoch [3/8], Step [400/1548], Loss: 0.3369\n",
            "Epoch [3/8], Step [500/1548], Loss: 0.3686\n",
            "Epoch [3/8], Step [600/1548], Loss: 0.3507\n",
            "Epoch [3/8], Step [700/1548], Loss: 0.3256\n",
            "Epoch [3/8], Step [800/1548], Loss: 0.3480\n",
            "Epoch [3/8], Step [900/1548], Loss: 0.2372\n",
            "Epoch [3/8], Step [1000/1548], Loss: 0.3551\n",
            "Epoch [3/8], Step [1100/1548], Loss: 0.3161\n",
            "Epoch [3/8], Step [1200/1548], Loss: 0.3577\n",
            "Epoch [3/8], Step [1300/1548], Loss: 0.3161\n",
            "Epoch [3/8], Step [1400/1548], Loss: 0.2626\n",
            "Epoch [3/8], Step [1500/1548], Loss: 0.2756\n",
            "Epoch [4/8], Step [100/1548], Loss: 0.3138\n",
            "Epoch [4/8], Step [200/1548], Loss: 0.2056\n",
            "Epoch [4/8], Step [300/1548], Loss: 0.2070\n",
            "Epoch [4/8], Step [400/1548], Loss: 0.3374\n",
            "Epoch [4/8], Step [500/1548], Loss: 0.3118\n",
            "Epoch [4/8], Step [600/1548], Loss: 0.3341\n",
            "Epoch [4/8], Step [700/1548], Loss: 0.2720\n",
            "Epoch [4/8], Step [800/1548], Loss: 0.2775\n",
            "Epoch [4/8], Step [900/1548], Loss: 0.2741\n",
            "Epoch [4/8], Step [1000/1548], Loss: 0.2501\n",
            "Epoch [4/8], Step [1100/1548], Loss: 0.2701\n",
            "Epoch [4/8], Step [1200/1548], Loss: 0.3432\n",
            "Epoch [4/8], Step [1300/1548], Loss: 0.2190\n",
            "Epoch [4/8], Step [1400/1548], Loss: 0.2943\n",
            "Epoch [4/8], Step [1500/1548], Loss: 0.1473\n",
            "Epoch [5/8], Step [100/1548], Loss: 0.2887\n",
            "Epoch [5/8], Step [200/1548], Loss: 0.2678\n",
            "Epoch [5/8], Step [300/1548], Loss: 0.2810\n",
            "Epoch [5/8], Step [400/1548], Loss: 0.2902\n",
            "Epoch [5/8], Step [500/1548], Loss: 0.2820\n",
            "Epoch [5/8], Step [600/1548], Loss: 0.2255\n",
            "Epoch [5/8], Step [700/1548], Loss: 0.2333\n",
            "Epoch [5/8], Step [800/1548], Loss: 0.2550\n",
            "Epoch [5/8], Step [900/1548], Loss: 0.2041\n",
            "Epoch [5/8], Step [1000/1548], Loss: 0.2773\n",
            "Epoch [5/8], Step [1100/1548], Loss: 0.2870\n",
            "Epoch [5/8], Step [1200/1548], Loss: 0.2767\n",
            "Epoch [5/8], Step [1300/1548], Loss: 0.3058\n",
            "Epoch [5/8], Step [1400/1548], Loss: 0.1714\n",
            "Epoch [5/8], Step [1500/1548], Loss: 0.1310\n",
            "Epoch [6/8], Step [100/1548], Loss: 0.2517\n",
            "Epoch [6/8], Step [200/1548], Loss: 0.3007\n",
            "Epoch [6/8], Step [300/1548], Loss: 0.2055\n",
            "Epoch [6/8], Step [400/1548], Loss: 0.2123\n",
            "Epoch [6/8], Step [500/1548], Loss: 0.2961\n",
            "Epoch [6/8], Step [600/1548], Loss: 0.3326\n",
            "Epoch [6/8], Step [700/1548], Loss: 0.2488\n",
            "Epoch [6/8], Step [800/1548], Loss: 0.3537\n",
            "Epoch [6/8], Step [900/1548], Loss: 0.1496\n",
            "Epoch [6/8], Step [1000/1548], Loss: 0.2621\n",
            "Epoch [6/8], Step [1100/1548], Loss: 0.2990\n",
            "Epoch [6/8], Step [1200/1548], Loss: 0.2573\n",
            "Epoch [6/8], Step [1300/1548], Loss: 0.2280\n",
            "Epoch [6/8], Step [1400/1548], Loss: 0.2193\n",
            "Epoch [6/8], Step [1500/1548], Loss: 0.4062\n",
            "Epoch [7/8], Step [100/1548], Loss: 0.2131\n",
            "Epoch [7/8], Step [200/1548], Loss: 0.1685\n",
            "Epoch [7/8], Step [300/1548], Loss: 0.2702\n",
            "Epoch [7/8], Step [400/1548], Loss: 0.2505\n",
            "Epoch [7/8], Step [500/1548], Loss: 0.2439\n",
            "Epoch [7/8], Step [600/1548], Loss: 0.1681\n",
            "Epoch [7/8], Step [700/1548], Loss: 0.1715\n",
            "Epoch [7/8], Step [800/1548], Loss: 0.2318\n",
            "Epoch [7/8], Step [900/1548], Loss: 0.2767\n",
            "Epoch [7/8], Step [1000/1548], Loss: 0.1929\n",
            "Epoch [7/8], Step [1100/1548], Loss: 0.2194\n",
            "Epoch [7/8], Step [1200/1548], Loss: 0.1847\n",
            "Epoch [7/8], Step [1300/1548], Loss: 0.2719\n",
            "Epoch [7/8], Step [1400/1548], Loss: 0.2773\n",
            "Epoch [7/8], Step [1500/1548], Loss: 0.1650\n",
            "Epoch [8/8], Step [100/1548], Loss: 0.1444\n",
            "Epoch [8/8], Step [200/1548], Loss: 0.2025\n",
            "Epoch [8/8], Step [300/1548], Loss: 0.1928\n",
            "Epoch [8/8], Step [400/1548], Loss: 0.2076\n",
            "Epoch [8/8], Step [500/1548], Loss: 0.2846\n",
            "Epoch [8/8], Step [600/1548], Loss: 0.1895\n",
            "Epoch [8/8], Step [700/1548], Loss: 0.2040\n",
            "Epoch [8/8], Step [800/1548], Loss: 0.2665\n",
            "Epoch [8/8], Step [900/1548], Loss: 0.1614\n",
            "Epoch [8/8], Step [1000/1548], Loss: 0.1650\n",
            "Epoch [8/8], Step [1100/1548], Loss: 0.1942\n",
            "Epoch [8/8], Step [1200/1548], Loss: 0.2058\n",
            "Epoch [8/8], Step [1300/1548], Loss: 0.1428\n",
            "Epoch [8/8], Step [1400/1548], Loss: 0.3001\n",
            "Epoch [8/8], Step [1500/1548], Loss: 0.1855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FMzerbeI6u68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fc108e6-32fa-4556-cf26-bf4bd1521199"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in loader_valid:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "          \n",
        "    print('Test Accuracy of the model on the 22003 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 22003 test images: 90.18770167704405 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "togFRWma13XB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_valid = MyDataset(df_data=sub, data_dir=test_path, transform=trans_valid)\n",
        "loader_test = DataLoader(dataset = dataset_valid, batch_size=32, shuffle=False, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aL1Ayt0U1GoK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "preds = []\n",
        "for batch_i, (data, target) in enumerate(loader_test):\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    output = model(data)\n",
        "\n",
        "    pr = output[:,1].detach().cpu().numpy()\n",
        "    for i in pr:\n",
        "        preds.append(i)\n",
        "\n",
        "sub['label'] = preds\n",
        "sub.to_csv('sub.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3faWi5_z4FqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dec25bf-a9c0-4f2a-924d-532e6555fbc1"
      },
      "cell_type": "code",
      "source": [
        "sub.shape, len(preds)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((57458, 2), 57458)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "metadata": {
        "id": "gjNe5j27YH1Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('sub.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaJ_tAdZBksm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HyT7VwWV6KHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fast Keras**"
      ]
    },
    {
      "metadata": {
        "id": "pHLS3Ijyrudo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adamax\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63igqr-6jFLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1df1da54-9451-4015-9dba-d4a51026acfc"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train_labels.csv')\n",
        "df[\"id\"]=df[\"id\"].apply(lambda x : x +\".tif\")\n",
        "df['label'] = df['label'].astype('str')\n",
        "df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f38a6374c348f90b587e046aac6079959adf3835.tif</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77.tif</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>755db6279dae599ebb4d39a9123cce439965282d.tif</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08.tif</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>068aba587a4950175d04c680d38943fd488d6a9d.tif</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             id label\n",
              "0  f38a6374c348f90b587e046aac6079959adf3835.tif     0\n",
              "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77.tif     1\n",
              "2  755db6279dae599ebb4d39a9123cce439965282d.tif     0\n",
              "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08.tif     0\n",
              "4  068aba587a4950175d04c680d38943fd488d6a9d.tif     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "vYHGV6wZ8x5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "74aff98c-691d-417f-960d-5fd70da596b0"
      },
      "cell_type": "code",
      "source": [
        "# num_val\n",
        "val = .1\n",
        "\n",
        "# Generator for data augmentation\n",
        "datagen= ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    samplewise_std_normalization= True,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=90,\n",
        "    zoom_range=0.2, \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.05,\n",
        "    channel_shift_range=0.1,\n",
        "    validation_split=val)\n",
        "\n",
        "\n",
        "# Generator for train data\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    directory='train',\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    subset=\"training\",\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(96,96))\n",
        "\n",
        "\n",
        "# Generator for test data\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    directory='train',\n",
        "    x_col=\"id\",\n",
        "    y_col=\"label\",\n",
        "    subset=\"validation\",\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(96,96))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:353: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 198023 images belonging to 2 classes.\n",
            "Found 22002 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vIC1qml09VNI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ]
    },
    {
      "metadata": {
        "id": "jT2l7Vtxru6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=3, input_shape=(96,96,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vo3JeyXntzkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adamax = Adamax(lr=0.02,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.999,\n",
        "                epsilon=None,\n",
        "                decay=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJOzdhLRrvEL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=adamax,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XsgMNxoBrvMK",
        "colab_type": "code",
        "outputId": "6f4120ca-0172-432a-a8f5-3755dd6eb006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 96, 96, 16)        448       \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 96, 96, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 96, 96, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 48, 48, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 48, 48, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 9217      \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 33,249\n",
            "Trainable params: 33,025\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5NqMN2DH6RUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e1f14f42-9f40-4ea1-8488-eea602c17596"
      },
      "cell_type": "code",
      "source": [
        "# Начало обучения\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=train_generator.n//128, \n",
        "                              validation_data=valid_generator,\n",
        "                              validation_steps=valid_generator.n//128,\n",
        "                              epochs=5,\n",
        "                              verbose=1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1547/1547 [==============================] - 1204s 779ms/step - loss: 6.5364 - acc: 0.5942 - val_loss: 6.4858 - val_acc: 0.5976\n",
            "Epoch 2/5\n",
            "1547/1547 [==============================] - 1203s 778ms/step - loss: 6.5303 - acc: 0.5948 - val_loss: 6.5131 - val_acc: 0.5959\n",
            "Epoch 3/5\n",
            "1547/1547 [==============================] - 1207s 780ms/step - loss: 6.5287 - acc: 0.5949 - val_loss: 6.5419 - val_acc: 0.5941\n",
            "Epoch 4/5\n",
            "1547/1547 [==============================] - 1209s 782ms/step - loss: 6.5190 - acc: 0.5955 - val_loss: 6.5433 - val_acc: 0.5940\n",
            "Epoch 5/5\n",
            "1547/1547 [==============================] - 1167s 754ms/step - loss: 6.5260 - acc: 0.5951 - val_loss: 6.4490 - val_acc: 0.5999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7wWhV87H6RQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPg3YVCP6RK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y62VHB7R6RHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7vD0_tR6RDI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4hgMTMn6Q7v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3GboUD_vXNe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVQ0fpiJvXbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9SmvW8aqvXVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
